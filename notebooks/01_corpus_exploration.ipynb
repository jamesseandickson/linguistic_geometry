{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf02093",
   "metadata": {},
   "source": [
    "# ðŸ“š Corpus Exploration\n",
    "\n",
    "This notebook explores the semantic concept corpus and demonstrates the loader functionality.\n",
    "\n",
    "**Goal:** Understand what concepts we have and which domains might map to different geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a549689c",
   "metadata": {},
   "source": [
    "## 1. Load the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b90a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from corpora.loader import load_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e1114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: semantic_concepts_v0\n",
      "Version: 0\n",
      "Language: en\n",
      "Total clusters: 20\n",
      "Total expressions: 400\n"
     ]
    }
   ],
   "source": [
    "# Load the corpus\n",
    "corpus = load_corpus(\"semantic_concepts_v0\")\n",
    "\n",
    "print(f\"Loaded: {corpus.corpus_id}\")\n",
    "print(f\"Version: {corpus.version}\")\n",
    "print(f\"Language: {corpus.language}\")\n",
    "print(f\"Total clusters: {len(corpus)}\")\n",
    "print(f\"Total expressions: {len(corpus.get_all_expressions())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ffcc5",
   "metadata": {},
   "source": [
    "## 2. Explore Domains\n",
    "\n",
    "What semantic domains do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4accecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available domains:\n",
      "['emotion', 'epistemic', 'evidentiality', 'modality', 'modification', 'motion', 'perception', 'physical_extent', 'quantity', 'social_structure', 'social_style', 'space', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available domains:\")\n",
    "print(sorted(corpus.domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ccfbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Domain statistics:\n",
      "------------------------------------------------------------\n",
      "emotion              |  2 clusters |  40 expressions\n",
      "epistemic            |  1 clusters |  20 expressions\n",
      "evidentiality        |  1 clusters |  20 expressions\n",
      "modality             |  2 clusters |  40 expressions\n",
      "modification         |  1 clusters |  20 expressions\n",
      "motion               |  1 clusters |  20 expressions\n",
      "perception           |  1 clusters |  20 expressions\n",
      "physical_extent      |  1 clusters |  20 expressions\n",
      "quantity             |  1 clusters |  20 expressions\n",
      "social_structure     |  2 clusters |  40 expressions\n",
      "social_style         |  2 clusters |  40 expressions\n",
      "space                |  3 clusters |  60 expressions\n",
      "time                 |  2 clusters |  40 expressions\n"
     ]
    }
   ],
   "source": [
    "# Domain breakdown\n",
    "print(\"\\nDomain statistics:\")\n",
    "print(\"-\" * 60)\n",
    "for domain in sorted(corpus.domains):\n",
    "    clusters = corpus.filter_by_domain(domain)\n",
    "    total_expr = sum(len(c) for c in clusters)\n",
    "    print(f\"{domain:20s} | {len(clusters):2d} clusters | {total_expr:3d} expressions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac833cf6",
   "metadata": {},
   "source": [
    "## 3. Examine Specific Domains\n",
    "\n",
    "Let's look at domains that might have interesting geometric properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3e13b",
   "metadata": {},
   "source": [
    "### Emotion (Potential Spinor/Polarity Candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd54db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion domain: 2 clusters\n",
      "\n",
      "Subdomain: valence_mixed\n",
      "Concept: affective_valence_mixed\n",
      "Size: 20 expressions\n",
      "Examples: ['happy', 'joyful', 'content', 'pleased', 'cheerful', 'delighted', 'ecstatic', 'satisfied', 'glad', 'hopeful']\n",
      "\n",
      "Subdomain: arousal_mixed\n",
      "Concept: emotion_arousal_mixed\n",
      "Size: 20 expressions\n",
      "Examples: ['calm', 'relaxed', 'tranquil', 'serene', 'still', 'restless', 'tense', 'anxious', 'keyed up', 'nervous']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emotion_clusters = corpus.filter_by_domain(\"emotion\")\n",
    "\n",
    "print(f\"Emotion domain: {len(emotion_clusters)} clusters\\n\")\n",
    "for cluster in emotion_clusters:\n",
    "    print(f\"Subdomain: {cluster.subdomain}\")\n",
    "    print(f\"Concept: {cluster.concept}\")\n",
    "    print(f\"Size: {len(cluster)} expressions\")\n",
    "    print(f\"Examples: {cluster.expressions[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53878642",
   "metadata": {},
   "source": [
    "### Social Structure (Potential Hyperbolic/Hierarchy Candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a439996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social structure domain: 2 clusters\n",
      "\n",
      "Subdomain: status_role\n",
      "Concept: social_status_roles\n",
      "Size: 20 expressions\n",
      "Examples: ['peasant', 'worker', 'assistant', 'employee', 'staff', 'junior', 'colleague', 'senior', 'manager', 'boss']\n",
      "\n",
      "Subdomain: power\n",
      "Concept: power_dynamics_language\n",
      "Size: 20 expressions\n",
      "Examples: ['powerless', 'weak', 'vulnerable', 'dependent', 'subordinate', 'obedient', 'compliant', 'modest', 'confident', 'assertive']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "social_clusters = corpus.filter_by_domain(\"social_structure\")\n",
    "\n",
    "print(f\"Social structure domain: {len(social_clusters)} clusters\\n\")\n",
    "for cluster in social_clusters:\n",
    "    print(f\"Subdomain: {cluster.subdomain}\")\n",
    "    print(f\"Concept: {cluster.concept}\")\n",
    "    print(f\"Size: {len(cluster)} expressions\")\n",
    "    print(f\"Examples: {cluster.expressions[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efa722",
   "metadata": {},
   "source": [
    "### Space (Potential Rotation/Axis Candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7a6d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space domain: 3 clusters\n",
      "\n",
      "Subdomain: vertical\n",
      "Concept: vertical_spatial_terms\n",
      "Size: 20 expressions\n",
      "Examples: ['below', 'under', 'underneath', 'beneath', 'down', 'low', 'lower', 'bottom', 'ground-level', 'level']\n",
      "\n",
      "Subdomain: horizontal\n",
      "Concept: horizontal_spatial_terms\n",
      "Size: 20 expressions\n",
      "Examples: ['left', 'right', 'centre', 'middle', 'edge', 'far left', 'far right', 'near', 'far', 'beside']\n",
      "\n",
      "Subdomain: distance\n",
      "Concept: spatial_distance_terms\n",
      "Size: 20 expressions\n",
      "Examples: ['touching', 'adjacent', 'close', 'nearby', 'near', 'within reach', 'a short way', 'not far', 'far', 'distant']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "space_clusters = corpus.filter_by_domain(\"space\")\n",
    "\n",
    "print(f\"Space domain: {len(space_clusters)} clusters\\n\")\n",
    "for cluster in space_clusters:\n",
    "    print(f\"Subdomain: {cluster.subdomain}\")\n",
    "    print(f\"Concept: {cluster.concept}\")\n",
    "    print(f\"Size: {len(cluster)} expressions\")\n",
    "    print(f\"Examples: {cluster.expressions[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bbb647",
   "metadata": {},
   "source": [
    "### Time (Potential Cyclic/Phase Candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f29570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time domain: 2 clusters\n",
      "\n",
      "Subdomain: order\n",
      "Concept: temporal_order_terms\n",
      "Size: 20 expressions\n",
      "Examples: ['before', 'earlier', 'previously', 'once', 'formerly', 'already', 'now', 'currently', 'presently', 'immediately']\n",
      "\n",
      "Subdomain: cycle\n",
      "Concept: time_of_day_cycle\n",
      "Size: 20 expressions\n",
      "Examples: ['dawn', 'daybreak', 'sunrise', 'early morning', 'late morning', 'noon', 'midday', 'afternoon', 'midafternoon', 'evening']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_clusters = corpus.filter_by_domain(\"time\")\n",
    "\n",
    "print(f\"Time domain: {len(time_clusters)} clusters\\n\")\n",
    "for cluster in time_clusters:\n",
    "    print(f\"Subdomain: {cluster.subdomain}\")\n",
    "    print(f\"Concept: {cluster.concept}\")\n",
    "    print(f\"Size: {len(cluster)} expressions\")\n",
    "    print(f\"Examples: {cluster.expressions[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbad0d5",
   "metadata": {},
   "source": [
    "## 4. Cluster Size Distribution\n",
    "\n",
    "How are expressions distributed across clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9f7028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster size statistics:\n",
      "  Min: 20\n",
      "  Max: 20\n",
      "  Mean: 20.0\n",
      "  Total expressions: 400\n"
     ]
    }
   ],
   "source": [
    "cluster_sizes = [len(c) for c in corpus.clusters]\n",
    "\n",
    "print(f\"Cluster size statistics:\")\n",
    "print(f\"  Min: {min(cluster_sizes)}\")\n",
    "print(f\"  Max: {max(cluster_sizes)}\")\n",
    "print(f\"  Mean: {sum(cluster_sizes) / len(cluster_sizes):.1f}\")\n",
    "print(f\"  Total expressions: {sum(cluster_sizes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b7b32",
   "metadata": {},
   "source": [
    "## 5. All Clusters Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7ef504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All clusters:\n",
      "================================================================================\n",
      " 1. emotion              / valence_mixed             (20 expr)\n",
      "    affective_valence_mixed\n",
      "    Examples: happy, joyful, content, pleased, cheerful...\n",
      "\n",
      " 2. emotion              / arousal_mixed             (20 expr)\n",
      "    emotion_arousal_mixed\n",
      "    Examples: calm, relaxed, tranquil, serene, still...\n",
      "\n",
      " 3. perception           / temperature_subjective    (20 expr)\n",
      "    subjective_temperature_scale\n",
      "    Examples: freezing, icy, bitter, chilly, cold...\n",
      "\n",
      " 4. physical_extent      / size                      (20 expr)\n",
      "    size_extent_scale\n",
      "    Examples: tiny, minuscule, small, compact, little...\n",
      "\n",
      " 5. motion               / speed                     (20 expr)\n",
      "    motion_speed_scale\n",
      "    Examples: motionless, still, sluggish, slow, unhurried...\n",
      "\n",
      " 6. social_structure     / status_role               (20 expr)\n",
      "    social_status_roles\n",
      "    Examples: peasant, worker, assistant, employee, staff...\n",
      "\n",
      " 7. social_structure     / power                     (20 expr)\n",
      "    power_dynamics_language\n",
      "    Examples: powerless, weak, vulnerable, dependent, subordinate...\n",
      "\n",
      " 8. epistemic            / certainty                 (20 expr)\n",
      "    epistemic_certainty_scale\n",
      "    Examples: certain, sure, convinced, confident, clear...\n",
      "\n",
      " 9. quantity             / amount                    (20 expr)\n",
      "    quantity_magnitude_mixed\n",
      "    Examples: none, zero, scarce, little, few...\n",
      "\n",
      "10. time                 / order                     (20 expr)\n",
      "    temporal_order_terms\n",
      "    Examples: before, earlier, previously, once, formerly...\n",
      "\n",
      "11. time                 / cycle                     (20 expr)\n",
      "    time_of_day_cycle\n",
      "    Examples: dawn, daybreak, sunrise, early morning, late morning...\n",
      "\n",
      "12. space                / vertical                  (20 expr)\n",
      "    vertical_spatial_terms\n",
      "    Examples: below, under, underneath, beneath, down...\n",
      "\n",
      "13. space                / horizontal                (20 expr)\n",
      "    horizontal_spatial_terms\n",
      "    Examples: left, right, centre, middle, edge...\n",
      "\n",
      "14. space                / distance                  (20 expr)\n",
      "    spatial_distance_terms\n",
      "    Examples: touching, adjacent, close, nearby, near...\n",
      "\n",
      "15. social_style         / politeness                (20 expr)\n",
      "    politeness_greetings_and_appeals\n",
      "    Examples: hey, hi, hello, good morning, good afternoon...\n",
      "\n",
      "16. social_style         / formality                 (20 expr)\n",
      "    formality_lexical_variants\n",
      "    Examples: kids, children, offspring, dad, father...\n",
      "\n",
      "17. modification         / intensity                 (20 expr)\n",
      "    general_intensity_modifiers\n",
      "    Examples: slightly, a bit, somewhat, rather, fairly...\n",
      "\n",
      "18. modality             / obligation_permission     (20 expr)\n",
      "    obligation_and_permission_modals\n",
      "    Examples: must, have to, need to, ought to, should...\n",
      "\n",
      "19. modality             / possibility               (20 expr)\n",
      "    possibility_and_likelihood_adverbs\n",
      "    Examples: certainly, definitely, surely, probably, likely...\n",
      "\n",
      "20. evidentiality        / source_of_information     (20 expr)\n",
      "    evidence_source_expressions\n",
      "    Examples: I saw, I heard, they said, it seems, it appears...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"All clusters:\")\n",
    "print(\"=\" * 80)\n",
    "for i, cluster in enumerate(corpus.clusters, 1):\n",
    "    print(f\"{i:2d}. {cluster.domain:20s} / {cluster.subdomain:25s} ({len(cluster):2d} expr)\")\n",
    "    print(f\"    {cluster.concept}\")\n",
    "    print(f\"    Examples: {', '.join(cluster.expressions[:5])}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b98f6",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Now that we understand the corpus structure, we can:\n",
    "\n",
    "1. **Test different geometries** on different domains\n",
    "2. **Measure compression** (can we represent these concepts in lower dimensions?)\n",
    "3. **Compare distortion** across geometries\n",
    "4. **Identify which geometry fits which domain best**\n",
    "\n",
    "### Hypotheses to Test:\n",
    "\n",
    "- **Emotion** â†’ Spinor/SU(2) (polarity: happy â†” sad)\n",
    "- **Social structure** â†’ Hyperbolic (hierarchy: employee â†’ manager â†’ CEO)\n",
    "- **Space** â†’ Rotations/SO(3) (axes: left â†” right, up â†” down)\n",
    "- **Time** â†’ Cyclic/Phase (tense cycles, aspect)\n",
    "- **Modality** â†’ ? (to be discovered)\n",
    "\n",
    "The loader is **geometry-agnostic** â€” experiments will discover the truth."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
