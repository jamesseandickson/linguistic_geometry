{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a907fc1",
   "metadata": {},
   "source": [
    "# Encoder Exploration\n",
    "\n",
    "This notebook explores different text encoders for the Linguistic Geometry project.\n",
    "\n",
    "**What we'll test:**\n",
    "1. Basic encoding functionality\n",
    "2. Semantic similarity patterns\n",
    "3. Corpus encoding performance\n",
    "4. Model comparisons\n",
    "\n",
    "**Goal:** Understand how different encoders represent semantic concepts as numerical embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586a1bf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from encoders import SentenceTransformerEncoder\n",
    "from corpora.loader import load_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa052c7",
   "metadata": {},
   "source": [
    "## Test 1: Basic Encoding Functionality\n",
    "\n",
    "Let's start by testing that our encoder can convert text to embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Testing Basic Encoding\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Initialize encoder\n",
    "print(\"Loading encoder (all-MiniLM-L6-v2)...\")\n",
    "encoder = SentenceTransformerEncoder()\n",
    "print(f\"âœ“ Encoder loaded: {encoder}\")\n",
    "print(f\"  Embedding dimension: {encoder.embedding_dim}D\")\n",
    "print()\n",
    "\n",
    "# Test single string\n",
    "text = \"hello world\"\n",
    "embedding = encoder.encode(text)\n",
    "print(f\"Single text: '{text}'\")\n",
    "print(f\"  Embedding shape: {embedding.shape}\")\n",
    "print(f\"  First 5 values: {embedding[0, :5]}\")\n",
    "print()\n",
    "\n",
    "# Test multiple strings\n",
    "texts = [\"happy\", \"sad\", \"joyful\", \"miserable\"]\n",
    "embeddings = encoder.encode(texts)\n",
    "print(f\"Multiple texts: {texts}\")\n",
    "print(f\"  Embeddings shape: {embeddings.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea81c44",
   "metadata": {},
   "source": [
    "## Test 2: Semantic Similarity\n",
    "\n",
    "Let's test that semantically similar words have similar embeddings.\n",
    "We'll compute cosine similarities between word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Testing Semantic Similarity\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "encoder = SentenceTransformerEncoder()\n",
    "\n",
    "# Encode words\n",
    "words = [\"happy\", \"joyful\", \"sad\", \"freezing\", \"hot\"]\n",
    "embeddings = encoder.encode(words)\n",
    "\n",
    "# Compute cosine similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"Cosine similarities:\")\n",
    "print(f\"{'':12s}\", end=\"\")\n",
    "for word in words:\n",
    "    print(f\"{word:10s}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    print(f\"{word:12s}\", end=\"\")\n",
    "    for j in range(len(words)):\n",
    "        print(f\"{similarities[i, j]:10.3f}\", end=\"\")\n",
    "    print()\n",
    "print()\n",
    "\n",
    "# Check specific pairs\n",
    "happy_joyful = similarities[0, 1]\n",
    "happy_sad = similarities[0, 2]\n",
    "happy_freezing = similarities[0, 3]\n",
    "\n",
    "print(\"Expected patterns:\")\n",
    "print(f\"  happy â†” joyful:   {happy_joyful:.3f} (should be high)\")\n",
    "print(f\"  happy â†” sad:      {happy_sad:.3f} (should be medium)\")\n",
    "print(f\"  happy â†” freezing: {happy_freezing:.3f} (should be low)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569910c",
   "metadata": {},
   "source": [
    "## Test 3: Corpus Encoding\n",
    "\n",
    "Now let's test encoding a concept cluster from our semantic corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eaedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Testing Corpus Encoding\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Load corpus\n",
    "corpus = load_corpus(\"semantic_concepts_v0\")\n",
    "print(f\"Loaded corpus: {corpus.corpus_id}\")\n",
    "print(f\"Total clusters: {len(corpus)}\")\n",
    "print()\n",
    "\n",
    "# Get first cluster\n",
    "cluster = corpus.clusters[0]\n",
    "print(f\"Test cluster: {cluster.domain}/{cluster.subdomain}\")\n",
    "print(f\"Concept: {cluster.concept}\")\n",
    "print(f\"Size: {len(cluster)} expressions\")\n",
    "print(f\"Examples: {', '.join(cluster.expressions[:5])}\")\n",
    "print()\n",
    "\n",
    "# Encode cluster\n",
    "encoder = SentenceTransformerEncoder()\n",
    "embeddings = encoder.encode(cluster.expressions, show_progress_bar=True)\n",
    "\n",
    "print(f\"âœ“ Encoded {len(cluster)} expressions\")\n",
    "print(f\"  Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"  Memory: {embeddings.nbytes / 1024:.1f} KB\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f9b62",
   "metadata": {},
   "source": [
    "## Test 4: Model Comparison\n",
    "\n",
    "Let's compare different sentence-transformer models to see their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec955e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Comparing Different Models\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "models = [\n",
    "    (\"all-MiniLM-L6-v2\", \"Fast & lightweight\"),\n",
    "    (\"all-mpnet-base-v2\", \"High quality\"),\n",
    "]\n",
    "\n",
    "test_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "for model_name, description in models:\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  Description: {description}\")\n",
    "    \n",
    "    try:\n",
    "        encoder = SentenceTransformerEncoder(model_name)\n",
    "        embedding = encoder.encode(test_text)\n",
    "        \n",
    "        print(f\"  âœ“ Dimension: {encoder.embedding_dim}D\")\n",
    "        print(f\"  âœ“ Shape: {embedding.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error: {e}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db9266",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic Encoding** - Converting text to numerical embeddings\n",
    "2. **Semantic Similarity** - Similar words have similar embeddings\n",
    "3. **Corpus Integration** - Encoding concept clusters from our semantic corpus\n",
    "4. **Model Comparison** - Different models have different characteristics\n",
    "\n",
    "**Next Steps:**\n",
    "- Connect these encoders to the geometry fitting system\n",
    "- Test which geometric structures best explain semantic concepts\n",
    "- Discover if emotions, temperatures, etc. have intrinsic geometric patterns\n",
    "\n",
    "**Key Insight:** We now have a working system to convert semantic concepts into numerical representations that can be analyzed for geometric structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ‰ Encoder exploration complete!\")\n",
    "print(\"Ready to discover geometric patterns in language!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
